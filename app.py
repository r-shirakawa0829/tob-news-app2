import streamlit as st
import feedparser
import pandas as pd
import datetime
import os
import urllib.parse

# --- åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼šå…¬å…±ã‚’é™¤å¤– ---
def is_target_company(title, summary):
    text = (title + summary).lower()
    exclude_keywords = [
        "å¤§å­¦", "æ•™æˆ", "ç ”ç©¶å®¤", "å­¦ç”Ÿ", "é«˜æ ¡", "å­¦æ ¡",
        "å¸‚å½¹æ‰€", "çœŒåº", "éƒ½åº", "åŒºå½¹æ‰€", "å½¹å ´", "çœ", "åº", "å†…é–£",
        "è‡ªæ²»ä½“", "è¦³å…‰å”ä¼š", "ãƒ•ã‚§ã‚¹ãƒ†ã‚£ãƒãƒ«", "ç¥­ã‚Š", "å…¬å‹Ÿ", "å…¥æœ­",
        "æ©Ÿæ§‹", "è²¡å›£", "é€£åˆä¼š", "å”è­°ä¼š", "è­¦å¯Ÿ", "æ¶ˆé˜²"
    ]
    if any(k in text for k in exclude_keywords):
        return False
    return True

# --- â˜…ãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ãƒ»ãƒãƒƒãƒåº¦åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯â˜… ---
def analyze_business_tank_fit(title, summary):
    text = (title + summary).lower()
    tags = []
    score = 0

    # 1. åŸºæœ¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    growth_keywords = [
        "è²©è·¯æ‹¡å¤§", "è³‡é‡‘èª¿é”", "æ¡ç”¨å¼·åŒ–", "å¸ååˆä½µ", "æ–°è¦äº‹æ¥­", 
        "æ–°ã‚µãƒ¼ãƒ“ã‚¹", "ç¤¾å†…ä½“åˆ¶ã®ä¸€æ–°", "ãƒ—ãƒ¬ãƒªãƒªãƒ¼ã‚¹", "äº‹æ¥­æ‹¡å¤§",
        "ä¸Šå ´", "IPO", "é»’å­—åŒ–"
    ]
    for k in growth_keywords:
        if k in text:
            tags.append(f"ğŸ“ˆ{k}")
            score += 1

    # 2. ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ä¸è¶³ãƒ»è²©è·¯èª²é¡Œ
    partner_keywords = [
        "ææº", "å…±åŒç ”ç©¶", "å…±åŒé–‹ç™º", "å®Ÿè¨¼å®Ÿé¨“", "å”æ¥­", 
        "ã‚¢ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹", "ã‚ªãƒ¼ãƒ—ãƒ³ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "OEM", "ä»£ç†åº—å‹Ÿé›†",
        "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼å‹Ÿé›†", "è²©è·¯é–‹æ‹“"
    ]
    for k in partner_keywords:
        if k in text:
            tags.append(f"ğŸ¤{k}")
            score += 2 

    # 3. ãƒˆãƒƒãƒ—ã®æ±ºæ–­ãƒ»å¤‰é©æœŸ
    change_keywords = [
        "ç¤¾é•·å°±ä»»", "ä»£è¡¨å¤‰æ›´", "æ–°ä½“åˆ¶", "çµŒå–¶è¨ˆç”»", "åˆ·æ–°",
        "DXæ¨é€²", "ç”Ÿç”£æ€§å‘ä¸Š", "ã‚³ã‚¹ãƒˆå‰Šæ¸›"
    ]
    for k in change_keywords:
        if k in text:
            tags.append(f"âš¡{k}")
            score += 1

    return score, list(set(tags))

def fetch_all_sources():
    feeds = [
        "https://prtimes.jp/index.rdf",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("æ–°è¦äº‹æ¥­ é–‹å§‹") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("è³‡é‡‘èª¿é” å®Ÿæ–½") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("æ¥­å‹™ææº") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("è²©å£²ä»£ç†åº— å‹Ÿé›†") + "&hl=ja&gl=JP&ceid=JP:ja"
    ]
    
    now = datetime.datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    new_entries = []
    
    for url in feeds:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if is_target_company(entry.title, entry.summary):
                score, tags = analyze_business_tank_fit(entry.title, entry.summary)
                if score > 0:
                    title_clean = entry.title.replace("ã€", " ").replace("ã€‘", " ").replace("ã€Œ", " ").replace("ã€", " ")
                    company = title_clean.split("ãŒ")[0].split("ã®")[0].split("ã€")[0].strip()[:20]
                    new_entries.append([today_str, now.strftime("%H:%M"), company, entry.title, entry.link, score, ",".join(tags)])
    
    # â˜…ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ã—ã¦ãƒªã‚»ãƒƒãƒˆâ˜…
    db_file = "news_database_v2.csv"
    
    if new_entries:
        df_new = pd.DataFrame(new_entries, columns=["date", "time", "company", "title", "url", "score", "tags"])
        if os.path.exists(db_file):
            try:
                df_old = pd.read_csv(db_file)
                if "score" in df_old.columns:
                    df_final = pd.concat([df_new, df_old]).drop_duplicates(subset=["url"], keep="first")
                else:
                    df_final = df_new
            except:
                df_final = df_new
        else:
            df_final = df_new
        
        df_final = df_final.sort_values(by=["date", "score", "time"], ascending=[False, False, False])
        df_final.to_csv(db_file, index=False, encoding="utf_8_sig")
    return len(new_entries)

st.set_page_config(page_title="Business Tank Radar", layout="wide")

st.markdown("""
    <style>
    .stCard { background: white; border-left: 5px solid #ddd; padding: 15px; border-radius: 4px; margin-bottom: 10px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
    .score-s { border-left-color: #ff4b4b !important; background-color: #fff5f5; }
    .score-a { border-left-color: #ffa500 !important; }
    .tag { display: inline-block; background: #e9ecef; color: #444; padding: 2px 8px; border-radius: 12px; font-size: 11px; margin-right: 5px; margin-bottom: 4px; }
    .hot-tag { background: #ffe8e8; color: #d00; font-weight: bold; border: 1px solid #ffb3b3; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ¯ ãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ãƒ»è¦‹è¾¼ã¿å®¢ãƒ¬ãƒ¼ãƒ€ãƒ¼")

with st.sidebar:
    st.header("è¨­å®š")
    selected_date = st.date_input("æ—¥ä»˜é¸æŠ", datetime.date.today())
    st.divider()
    if st.button("ğŸ”„ æœ€æ–°è¦‹è¾¼ã¿å®¢ã‚’ã‚¹ã‚­ãƒ£ãƒ³"):
        with st.spinner("AIãŒãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ã«æœ€é©ãªä¼æ¥­ã‚’åˆ†æä¸­..."):
            count = fetch_all_sources()
            st.success(f"{count}ä»¶ã®ä¼æ¥­ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
            st.rerun()

# â˜…èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åã‚‚å¤‰æ›´â˜…
db_file = "news_database_v2.csv"
target_str = selected_date.strftime("%Y-%m-%d")

if os.path.exists(db_file):
    df = pd.read_csv(db_file)
    if "score" in df.columns:
        df = df.sort_values(by=["score", "time"], ascending=[False, False])
        
    display_df = df[df["date"] == target_str]
    st.subheader(f"ğŸ“… {target_str} ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ¨å¥¨ãƒªã‚¹ãƒˆ")
    
    if not display_df.empty:
        for _, row in display_df.iterrows():
            score = row.get('score', 0)
            card_class = "stCard"
            rank_label = ""
            if score >= 3:
                card_class += " score-s"
                rank_label = "ğŸ”¥ <span style='color:#d00;font-weight:bold'>Sãƒ©ãƒ³ã‚¯ï¼ˆæœ€å„ªå…ˆï¼‰</span>"
            elif score >= 2:
                card_class += " score-a"
                rank_label = "âœ¨ <span style='color:#e69500;font-weight:bold'>Aãƒ©ãƒ³ã‚¯ï¼ˆç‹™ã„ç›®ï¼‰</span>"
            
            tags_list = str(row['tags']).split(",")
            tag_html = ""
            for t in tags_list:
                if t and t != "nan":
                    style = "hot-tag" if any(w in t for w in ["è²©è·¯", "è³‡é‡‘", "æ¡ç”¨", "æ–°è¦", "ææº"]) else "tag"
                    tag_html += f'<span class="tag {style}">{t}</span>'

            st.markdown(f"""
            <div class="{card_class}">
                <div style="display:flex; justify-content:space-between; margin-bottom:5px;">
                    <small style="color:#666;">{row['time']} | {row['company']}</small>
                    <small>{rank_label}</small>
                </div>
                <a href="{row['url']}" target="_blank" style="text-decoration:none; color:#1f77b4; font-weight:bold; font-size:16px; display:block; margin-bottom:8px;">
                    {row['title']}
                </a>
                <div>{tag_html}</div>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("æ¡ä»¶ã«åˆè‡´ã™ã‚‹ä¼æ¥­ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
