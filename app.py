import streamlit as st
import feedparser
import pandas as pd
import datetime
import os
import urllib.parse

# --- åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼šå…¬å…±ã‚’é™¤å¤– ---
def is_target_company(title, summary):
    text = (title + summary).lower()
    # é™¤å¤–ãƒ¯ãƒ¼ãƒ‰ï¼ˆå®˜å…¬åºãƒ»æ•™è‚²æ©Ÿé–¢ãƒ»è‡ªæ²»ä½“ãªã©ï¼‰
    exclude_keywords = [
        "å¤§å­¦", "æ•™æˆ", "ç ”ç©¶å®¤", "å­¦ç”Ÿ", "é«˜æ ¡", "å­¦æ ¡",
        "å¸‚å½¹æ‰€", "çœŒåº", "éƒ½åº", "åŒºå½¹æ‰€", "å½¹å ´", "çœ", "åº", "å†…é–£",
        "è‡ªæ²»ä½“", "è¦³å…‰å”ä¼š", "ãƒ•ã‚§ã‚¹ãƒ†ã‚£ãƒãƒ«", "ç¥­ã‚Š", "å…¬å‹Ÿ", "å…¥æœ­",
        "æ©Ÿæ§‹", "è²¡å›£", "é€£åˆä¼š", "å”è­°ä¼š", "è­¦å¯Ÿ", "æ¶ˆé˜²"
    ]
    if any(k in text for k in exclude_keywords):
        return False
    return True

# --- â˜…ãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ãƒ»ãƒãƒƒãƒåº¦åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯â˜… ---
def analyze_business_tank_fit(title, summary):
    text = (title + summary).lower()
    tags = []
    score = 0

    # 1. ã€UseræŒ‡å®šã€‘æˆé•·ãƒ»å¤‰åŒ–ã®æ„æ€ï¼ˆåŸºæœ¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
    # ã“ã“ã«å½“ã¦ã¯ã¾ã‚Œã°ã€Œå•†è«‡ã®ä½™åœ°ã‚ã‚Šã€
    growth_keywords = [
        "è²©è·¯æ‹¡å¤§", "è³‡é‡‘èª¿é”", "æ¡ç”¨å¼·åŒ–", "å¸ååˆä½µ", "æ–°è¦äº‹æ¥­", 
        "æ–°ã‚µãƒ¼ãƒ“ã‚¹", "ç¤¾å†…ä½“åˆ¶ã®ä¸€æ–°", "ãƒ—ãƒ¬ãƒªãƒªãƒ¼ã‚¹", "äº‹æ¥­æ‹¡å¤§",
        "ä¸Šå ´", "IPO", "é»’å­—åŒ–"
    ]
    for k in growth_keywords:
        if k in text:
            tags.append(f"ğŸ“ˆ{k}")
            score += 1

    # 2. ã€Analysisã€‘ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ä¸è¶³ãƒ»è²©è·¯èª²é¡Œï¼ˆãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ãŒæœ€ã‚‚åˆºã•ã‚‹ï¼‰
    # è‡ªåŠ›ã§ã¯è§£æ±ºã§ããªã„ã€Œã¤ãªãåŠ›ã€ã‚’æ±‚ã‚ã¦ã„ã‚‹ä¼æ¥­
    partner_keywords = [
        "ææº", "å…±åŒç ”ç©¶", "å…±åŒé–‹ç™º", "å®Ÿè¨¼å®Ÿé¨“", "å”æ¥­", 
        "ã‚¢ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹", "ã‚ªãƒ¼ãƒ—ãƒ³ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "OEM", "ä»£ç†åº—å‹Ÿé›†",
        "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼å‹Ÿé›†", "è²©è·¯é–‹æ‹“"
    ]
    for k in partner_keywords:
        if k in text:
            tags.append(f"ğŸ¤{k}")
            score += 2 # å„ªå…ˆåº¦é«˜

    # 3. ã€Analysisã€‘ãƒˆãƒƒãƒ—ã®æ±ºæ–­ãƒ»å¤‰é©æœŸï¼ˆæ±ºè£è€…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæœ‰åŠ¹ï¼‰
    # ç¤¾é•·ãŒä»£ã‚ã£ãŸç›´å¾Œã‚„è¨ˆç”»ç™ºè¡¨æ™‚ã¯ã€æ–°ã—ã„ææ¡ˆã‚’èãè€³ã‚’æŒã£ã¦ã„ã‚‹
    change_keywords = [
        "ç¤¾é•·å°±ä»»", "ä»£è¡¨å¤‰æ›´", "æ–°ä½“åˆ¶", "çµŒå–¶è¨ˆç”»", "åˆ·æ–°",
        "DXæ¨é€²", "ç”Ÿç”£æ€§å‘ä¸Š", "ã‚³ã‚¹ãƒˆå‰Šæ¸›"
    ]
    for k in change_keywords:
        if k in text:
            tags.append(f"âš¡{k}")
            score += 1

    return score, list(set(tags)) # é‡è¤‡å‰Šé™¤

def fetch_all_sources():
    # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼šãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«çµã‚‹
    feeds = [
        "https://prtimes.jp/index.rdf",
        # æˆé•·ä¼æ¥­ã®å‹•ã
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("æ–°è¦äº‹æ¥­ é–‹å§‹") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("è³‡é‡‘èª¿é” å®Ÿæ–½") + "&hl=ja&gl=JP&ceid=JP:ja",
        # èª²é¡Œãƒ»ãƒ‹ãƒ¼ã‚º
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("æ¥­å‹™ææº") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("è²©å£²ä»£ç†åº— å‹Ÿé›†") + "&hl=ja&gl=JP&ceid=JP:ja"
    ]
    
    now = datetime.datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    new_entries = []
    
    for url in feeds:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if is_target_company(entry.title, entry.summary):
                # ãƒãƒƒãƒåº¦åˆ¤å®šã‚’å®Ÿè¡Œ
                score, tags = analyze_business_tank_fit(entry.title, entry.summary)
                
                # ã‚¹ã‚³ã‚¢ãŒ1ä»¥ä¸Šï¼ˆä½•ã‹ã—ã‚‰å¼•ã£ã‹ã‹ã‚‹ï¼‰ã®å ´åˆã®ã¿ãƒªã‚¹ãƒˆå…¥ã‚Š
                if score > 0:
                    title_clean = entry.title.replace("ã€", " ").replace("ã€‘", " ").replace("ã€Œ", " ").replace("ã€", " ")
                    company = title_clean.split("ãŒ")[0].split("ã®")[0].split("ã€")[0].strip()[:20]
                    
                    # ãƒªã‚¹ãƒˆã«è¿½åŠ ï¼ˆtagsã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ä¿å­˜ï¼‰
                    new_entries.append([today_str, now.strftime("%H:%M"), company, entry.title, entry.link, score, ",".join(tags)])
    
    db_file = "news_database.csv"
    if new_entries:
        df_new = pd.DataFrame(new_entries, columns=["date", "time", "company", "title", "url", "score", "tags"])
        if os.path.exists(db_file):
            df_old = pd.read_csv(db_file)
            # ã‚«ãƒ©ãƒ ä¸è¶³ã®æ—§ãƒ‡ãƒ¼ã‚¿å¯¾ç­–
            if "score" not in df_old.columns:
                df_final = df_new
            else:
                df_final = pd.concat([df_new, df_old]).drop_duplicates(subset=["url"], keep="first")
        else:
            df_final = df_new
        
        # ã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ï¼ˆï¼ã‚¢ãƒ„ã„ä¼æ¥­é †ï¼‰ã«ä¸¦ã³æ›¿ãˆ
        df_final = df_final.sort_values(by=["date", "score", "time"], ascending=[False, False, False])
        df_final.to_csv(db_file, index=False, encoding="utf_8_sig")
    return len(new_entries)

# --- ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.set_page_config(page_title="Business Tank Radar", layout="wide")

st.markdown("""
    <style>
    .stCard { background: white; border-left: 5px solid #ddd; padding: 15px; border-radius: 4px; margin-bottom: 10px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
    .score-s { border-left-color: #ff4b4b !important; background-color: #fff5f5; } /* ç‰¹Aè©•ä¾¡ */
    .score-a { border-left-color: #ffa500 !important; } /* Aè©•ä¾¡ */
    .tag { display: inline-block; background: #e9ecef; color: #444; padding: 2px 8px; border-radius: 12px; font-size: 11px; margin-right: 5px; margin-bottom: 4px; }
    .hot-tag { background: #ffe8e8; color: #d00; font-weight: bold; border: 1px solid #ffb3b3; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ¯ ãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ãƒ»è¦‹è¾¼ã¿å®¢ãƒ¬ãƒ¼ãƒ€ãƒ¼")

with st.sidebar:
    st.header("è¨­å®š")
    selected_date = st.date_input("æ—¥ä»˜é¸æŠ", datetime.date.today())
    st.divider()
    if st.button("ğŸ”„ æœ€æ–°è¦‹è¾¼ã¿å®¢ã‚’ã‚¹ã‚­ãƒ£ãƒ³"):
        with st.spinner("AIãŒãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ã«æœ€é©ãªä¼æ¥­ã‚’åˆ†æä¸­..."):
            count = fetch_all_sources()
            st.success(f"{count}ä»¶ã®ä¼æ¥­ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
            st.rerun()

db_file = "news_database.csv"
target_str = selected_date.strftime("%Y-%m-%d")

if os.path.exists(db_file):
    df = pd.read_csv(db_file)
    
    # ã‚¹ã‚³ã‚¢ã§é™é †ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã ãŒå¿µã®ãŸã‚
    if "score" in df.columns:
        df = df.sort_values(by=["score", "time"], ascending=[False, False])
        
    display_df = df[df["date"] == target_str]
    
    st.subheader(f"ğŸ“… {target_str} ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ¨å¥¨ãƒªã‚¹ãƒˆ")
    
    if not display_df.empty:
        for _, row in display_df.iterrows():
            # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸãƒ‡ã‚¶ã‚¤ãƒ³
            score = row.get('score', 0)
            card_class = "stCard"
            rank_label = ""
            
            if score >= 3: # è¤‡æ•°ã®æ¡ä»¶ã«ãƒ’ãƒƒãƒˆï¼ˆæ¿€ã‚¢ãƒ„ï¼‰
                card_class += " score-s"
                rank_label = "ğŸ”¥ <span style='color:#d00;font-weight:bold'>Sãƒ©ãƒ³ã‚¯ï¼ˆæœ€å„ªå…ˆï¼‰</span>"
            elif score >= 2:
                card_class += " score-a"
                rank_label = "âœ¨ <span style='color:#e69500;font-weight:bold'>Aãƒ©ãƒ³ã‚¯ï¼ˆç‹™ã„ç›®ï¼‰</span>"
            
            # ã‚¿ã‚°ã®ç”Ÿæˆ
            tags_list = str(row['tags']).split(",")
            tag_html = ""
            for t in tags_list:
                if t:
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ¯ãƒ¼ãƒ‰ã¯èµ¤ãå¼·èª¿
                    style = "hot-tag" if any(w in t for w in ["è²©è·¯", "è³‡é‡‘", "æ¡ç”¨", "æ–°è¦", "ææº"]) else "tag"
                    tag_html += f'<span class="tag {style}">{t}</span>'

            st.markdown(f"""
            <div class="{card_class}">
                <div style="display:flex; justify-content:space-between; margin-bottom:5px;">
                    <small style="color:#666;">{row['time']} | {row['company']}</small>
                    <small>{rank_label}</small>
                </div>
                <a href="{row['url']}" target="_blank" style="text-decoration:none; color:#1f77b4; font-weight:bold; font-size:16px; display:block; margin-bottom:8px;">
                    {row['title']}
                </a>
                <div>{tag_html}</div>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("æ¡ä»¶ã«åˆè‡´ã™ã‚‹ä¼æ¥­ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
