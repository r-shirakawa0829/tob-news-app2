import streamlit as st
import feedparser
import pandas as pd
import datetime
import os
import urllib.parse

# --- åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼šå…¬å…±ã‚’é™¤å¤– ---
def is_target_company(title, summary):
    text = (title + summary).lower()
    exclude_keywords = [
        "å¤§å­¦", "æ•™æˆ", "ç ”ç©¶å®¤", "å­¦ç”Ÿ", "é«˜æ ¡", "å­¦æ ¡",
        "å¸‚å½¹æ‰€", "çœŒåº", "éƒ½åº", "åŒºå½¹æ‰€", "å½¹å ´", "çœ", "åº", "å†…é–£",
        "è‡ªæ²»ä½“", "è¦³å…‰å”ä¼š", "ãƒ•ã‚§ã‚¹ãƒ†ã‚£ãƒãƒ«", "ç¥­ã‚Š", "å…¬å‹Ÿ", "å…¥æœ­",
        "æ©Ÿæ§‹", "è²¡å›£", "é€£åˆä¼š", "å”è­°ä¼š", "è­¦å¯Ÿ", "æ¶ˆé˜²"
    ]
    if any(k in text for k in exclude_keywords):
        return False
    return True

# --- â˜…ãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ãƒ»ãƒãƒƒãƒåº¦åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ”¹è‰¯ç‰ˆï¼‰â˜… ---
def analyze_business_tank_fit(title, summary):
    text = (title + summary).lower()
    tags = []
    score = 0

    # 1. ã€Crownã€‘è²©è·¯æ‹¡å¤§ãƒ»ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼å‹Ÿé›†ï¼ˆãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ç›´æ’ƒï¼‰
    # ã“ã‚ŒãŒã‚ã‚‹ä¼æ¥­ã¯ã€Œå£²ã‚Šå…ˆã€ã‚’æ¸‡æœ›ã—ã¦ã„ã‚‹ãŸã‚ã€æœ€å„ªå…ˆï¼ˆ+10ç‚¹ï¼‰
    crown_keywords = [
        "è²©è·¯æ‹¡å¤§", "è²©è·¯é–‹æ‹“", "è²©å£²åº—å‹Ÿé›†", "è²©å£²åº— å‹Ÿé›†", 
        "ä»£ç†åº—å‹Ÿé›†", "ä»£ç†åº— å‹Ÿé›†", "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼å‹Ÿé›†"
    ]
    for k in crown_keywords:
        if k in text:
            tags.append(f"ğŸ‘‘{k}")
            score += 10

    # 2. ã€Priorityã€‘æ”»ã‚ã®å§¿å‹¢ï¼ˆè³‡é‡‘ãƒ»æ–°ã‚µãƒ¼ãƒ“ã‚¹ï¼‰
    # å‹•ãå‡ºã™æº–å‚™ãŒæ•´ã£ãŸä¼æ¥­ï¼ˆ+3ç‚¹ï¼‰
    priority_keywords = [
        "è³‡é‡‘èª¿é”", "ç¬¬ä¸‰è€…å‰²å½“", "æ–°ã‚µãƒ¼ãƒ“ã‚¹", "æ–°å•†å“", 
        "ãƒ—ãƒ¬ãƒªãƒªãƒ¼ã‚¹", "ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹", "ãƒ­ãƒ¼ãƒ³ãƒ", "ç™ºå£²", "æä¾›é–‹å§‹"
    ]
    for k in priority_keywords:
        if k in text:
            tags.append(f"ğŸ”¥{k}")
            score += 3

    # 3. ã€Partnershipã€‘ææºãƒ»å”æ¥­ï¼ˆ+2ç‚¹ï¼‰
    partner_keywords = [
        "ææº", "å…±åŒç ”ç©¶", "å…±åŒé–‹ç™º", "å®Ÿè¨¼å®Ÿé¨“", "å”æ¥­", 
        "ã‚¢ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹", "ã‚ªãƒ¼ãƒ—ãƒ³ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "OEM"
    ]
    for k in partner_keywords:
        if k in text:
            tags.append(f"ğŸ¤{k}")
            score += 2 

    # 4. ã€Changeã€‘å¤‰åŒ–ã®äºˆå…†ï¼ˆ+1ç‚¹ï¼‰
    change_keywords = [
        "æ–°è¦äº‹æ¥­", "äº‹æ¥­æ‹¡å¤§", "ç¤¾é•·å°±ä»»", "æ–°ä½“åˆ¶", 
        "çµŒå–¶è¨ˆç”»", "åˆ·æ–°", "DX", "IPO", "é»’å­—åŒ–"
    ]
    for k in change_keywords:
        if k in text:
            tags.append(f"ğŸ“ˆ{k}")
            score += 1

    # 5. ã€Penaltyã€‘å¤§æ‰‹ãƒ»æœ‰åä¼æ¥­ã®æ¸›ç‚¹ï¼ˆ-10ç‚¹ï¼‰
    big_company_keywords = [
        "å¤§æ‰‹", "æœ€å¤§æ‰‹", "æ¥­ç•Œãƒˆãƒƒãƒ—", "æ±è¨¼ãƒ—ãƒ©ã‚¤ãƒ ", "è€èˆ—", 
        "æœ‰å", "ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹", "ã‚°ãƒ«ãƒ¼ãƒ—"
    ]
    for k in big_company_keywords:
        if k in text:
            score -= 10
            tags.append(f"ğŸ¢{k}(å¤§æ‰‹)")

    return score, list(set(tags))

def fetch_all_sources():
    # æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚‚ã€Œè²©è·¯æ‹¡å¤§ã€ã€Œè³‡é‡‘èª¿é”ã€ã«å¯„ã›ã‚‹
    feeds = [
        "https://prtimes.jp/index.rdf",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("è²©å£²åº—å‹Ÿé›† æ³•äºº") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("ä»£ç†åº—å‹Ÿé›† æ³•äºº") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("è³‡é‡‘èª¿é” å®Ÿæ–½") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("æ–°ã‚µãƒ¼ãƒ“ã‚¹ é–‹å§‹ æ³•äºº") + "&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.google.com/rss/search?q=" + urllib.parse.quote("è²©è·¯æ‹¡å¤§ ææº") + "&hl=ja&gl=JP&ceid=JP:ja"
    ]
    
    now = datetime.datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    new_entries = []
    
    for url in feeds:
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if is_target_company(entry.title, entry.summary):
                score, tags = analyze_business_tank_fit(entry.title, entry.summary)
                
                title_clean = entry.title.replace("ã€", " ").replace("ã€‘", " ").replace("ã€Œ", " ").replace("ã€", " ")
                company = title_clean.split("ãŒ")[0].split("ã®")[0].split("ã€")[0].strip()[:20]
                new_entries.append([today_str, now.strftime("%H:%M"), company, entry.title, entry.link, score, ",".join(tags)])
    
    # â˜…ãƒ•ã‚¡ã‚¤ãƒ«åã‚’v4ã«å¤‰æ›´â˜…
    db_file = "news_database_v4.csv"
    
    if new_entries:
        df_new = pd.DataFrame(new_entries, columns=["date", "time", "company", "title", "url", "score", "tags"])
        if os.path.exists(db_file):
            try:
                df_old = pd.read_csv(db_file)
                if "score" in df_old.columns:
                    df_final = pd.concat([df_new, df_old]).drop_duplicates(subset=["url"], keep="first")
                else:
                    df_final = df_new
            except:
                df_final = df_new
        else:
            df_final = df_new
        
        # ã‚¹ã‚³ã‚¢é †ã«ä¸¦ã³æ›¿ãˆï¼ˆè²©è·¯æ‹¡å¤§ç³»ãŒæœ€ä¸Šä½ã«æ¥ã‚‹ï¼‰
        df_final = df_final.sort_values(by=["date", "score", "time"], ascending=[False, False, False])
        df_final.to_csv(db_file, index=False, encoding="utf_8_sig")
    return len(new_entries)

st.set_page_config(page_title="Business Tank Radar", layout="wide")

st.markdown("""
    <style>
    .stCard { background: white; border-left: 5px solid #ddd; padding: 15px; border-radius: 4px; margin-bottom: 10px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
    
    /* ãƒ©ãƒ³ã‚¯ã”ã¨ã®è‰²è¨­å®š */
    .score-crown { border-left-color: #ff00ff !important; background-color: #fff0ff; } /* è²©è·¯æ‹¡å¤§ï¼ˆç´«ï¼‰ */
    .score-s { border-left-color: #ff4b4b !important; background-color: #fff5f5; } /* è³‡é‡‘èª¿é”ãªã©ï¼ˆèµ¤ï¼‰ */
    .score-a { border-left-color: #ffa500 !important; } /* ãã®ä»–ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ï¼‰ */
    
    .tag { display: inline-block; background: #e9ecef; color: #444; padding: 2px 8px; border-radius: 12px; font-size: 11px; margin-right: 5px; margin-bottom: 4px; }
    .crown-tag { background: #fce4ff; color: #a0f; font-weight: bold; border: 1px solid #e0b0ff; }
    .hot-tag { background: #ffe8e8; color: #d00; font-weight: bold; border: 1px solid #ffb3b3; }
    .big-tag { background: #ddd; color: #888; text-decoration: line-through; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ¯ ãƒ“ã‚¸ãƒã‚¹ã‚¿ãƒ³ã‚¯ãƒ»è¦‹è¾¼ã¿å®¢ãƒ¬ãƒ¼ãƒ€ãƒ¼")

with st.sidebar:
    st.header("è¨­å®š")
    selected_date = st.date_input("æ—¥ä»˜é¸æŠ", datetime.date.today())
    st.divider()
    if st.button("ğŸ”„ æœ€æ–°è¦‹è¾¼ã¿å®¢ã‚’ã‚¹ã‚­ãƒ£ãƒ³"):
        with st.spinner("ã€Œè²©è·¯æ‹¡å¤§ã€ã€Œè³‡é‡‘èª¿é”ã€ä¼æ¥­ã‚’å„ªå…ˆã‚¹ã‚­ãƒ£ãƒ³ä¸­..."):
            count = fetch_all_sources()
            st.success(f"{count}ä»¶ã®ä¼æ¥­ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
            st.rerun()

db_file = "news_database_v4.csv"
target_str = selected_date.strftime("%Y-%m-%d")

if os.path.exists(db_file):
    df = pd.read_csv(db_file)
    if "score" in df.columns:
        df = df.sort_values(by=["score", "time"], ascending=[False, False])
        
    display_df = df[df["date"] == target_str]
    st.subheader(f"ğŸ“… {target_str} ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ¨å¥¨ãƒªã‚¹ãƒˆ")
    
    if not display_df.empty:
        for _, row in display_df.iterrows():
            score = row.get('score', 0)
            card_class = "stCard"
            rank_label = ""
            
            # ãƒ©ãƒ³ã‚¯åˆ¤å®š
            if score >= 10: # è²©è·¯æ‹¡å¤§ãƒ»è²©å£²åº—å‹Ÿé›†
                card_class += " score-crown"
                rank_label = "ğŸ‘‘ <span style='color:#c0f;font-weight:bold'>è²©è·¯æ‹¡å¤§ãƒ‹ãƒ¼ã‚ºï¼ˆæ¿€ã‚¢ãƒ„ï¼‰</span>"
            elif score >= 3: # è³‡é‡‘èª¿é”ãƒ»æ–°ã‚µãƒ¼ãƒ“ã‚¹
                card_class += " score-s"
                rank_label = "ğŸ”¥ <span style='color:#d00;font-weight:bold'>æ”»ã‚ã®å§¿å‹¢ã‚ã‚Š</span>"
            elif score >= 1: # ãã®ä»–
                card_class += " score-a"
                rank_label = "âœ¨ <span style='color:#e69500;font-weight:bold'>å¤‰åŒ–ã®äºˆå…†</span>"
            elif score < 0:
                rank_label = "<span style='color:#999;font-size:10px;'>â€»å¤§æ‰‹ãƒ»å¯¾è±¡å¤–ã®å¯èƒ½æ€§</span>"
            
            tags_list = str(row['tags']).split(",")
            tag_html = ""
            for t in tags_list:
                if t and t != "nan":
                    if "ğŸ‘‘" in t:
                        style = "crown-tag"
                    elif "ğŸ”¥" in t or "ğŸ¤" in t:
                        style = "hot-tag"
                    elif "å¤§æ‰‹" in t or "ãƒ—ãƒ©ã‚¤ãƒ " in t:
                        style = "big-tag"
                    else:
                        style = "tag"
                    tag_html += f'<span class="tag {style}">{t}</span>'

            st.markdown(f"""
            <div class="{card_class}">
                <div style="display:flex; justify-content:space-between; margin-bottom:5px;">
                    <small style="color:#666;">{row['time']} | {row['company']}</small>
                    <small>{rank_label}</small>
                </div>
                <a href="{row['url']}" target="_blank" style="text-decoration:none; color:#1f77b4; font-weight:bold; font-size:16px; display:block; margin-bottom:8px;">
                    {row['title']}
                </a>
                <div>{tag_html}</div>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("æ¡ä»¶ã«åˆè‡´ã™ã‚‹ä¼æ¥­ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
